{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1631120440463,
     "user": {
      "displayName": "Dân Phạm",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01439254586035670376"
     },
     "user_tz": -420
    },
    "id": "dbVR-4SpkS54",
    "outputId": "231f5d62-593a-4511-b0c3-5622315f0105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anlab/Downloads/imageclassification/image_retrieval\n"
     ]
    }
   ],
   "source": [
    "%cd image_retrieval/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_local=\"/home/anlab/Downloads/imageclassification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5Q3M_ugkcWO"
   },
   "source": [
    "***Lấy file query ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VEXxH4jNo72V"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "def get_file_query():\n",
    "  path= \"gt_files/\"\n",
    "  list_gt = os.listdir(path)\n",
    "  list_files_query=[]\n",
    "  for file_name in list_gt:\n",
    "    name=file_name.split(\".\")[0].split(\"_\")[-1]\n",
    "    if(name==\"query\"):\n",
    "      list_files_query.append(file_name)\n",
    "  return list_files_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGzmYgTjlFt1"
   },
   "source": [
    "\n",
    "**lấy file ảnh tương ứng với querry (gồm 3 file good, oke, junk)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XDfXSsIszApF"
   },
   "outputs": [],
   "source": [
    "#get file good,oke,junk correspond\n",
    "def get_file_name(list_files_query, name):\n",
    "  list_files_name=[]\n",
    "  for query_file in list_files_query:\n",
    "    name_correspond= query_file.replace(\"query\",name)\n",
    "    list_files_name.append(name_correspond)\n",
    "  return list_files_name\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfqPHLJMlTs3"
   },
   "source": [
    "\n",
    "**lấy ảnh trong file query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kymc5gp21yB9"
   },
   "outputs": [],
   "source": [
    "def get_image_query(list_files_query):\n",
    "  list_image_query=[]\n",
    "  for query in list_files_query:\n",
    "    dir= path_local+\"/image_retrieval/gt_files/\"+query\n",
    "    with open(dir,\"r\") as f:\n",
    "      for line in f.readlines():\n",
    "        name_image= line.split(\" \")[0].split(\"_\",1)[1]+\".jpg\"\n",
    "        list_image_query.append(name_image)\n",
    "  return list_image_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Grj5Gnlrlar7"
   },
   "source": [
    "**lấy ảnh tương ứng của query với từng file good, oke, junk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-tu809Pl6ypj"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_image_correspond(file_name):\n",
    "  list_image_name= []\n",
    "  with open(\"gt_files/\"+file_name,\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "      list_image_name.append(line.split(\"\\n\")[0]+\".jpg\")\n",
    "  return list_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rmac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anlab/Downloads/imageclassification/image_retrieval/keras_rmac\n"
     ]
    }
   ],
   "source": [
    "%cd keras_rmac/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.layers import Lambda, Dense, TimeDistributed, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "import keras\n",
    "# from vgg16 import VGG16\n",
    "from RoiPooling import RoiPooling\n",
    "from PIL import Image,ImageOps\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import utils\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def rzac(im_tensor, z='m', l0=1, L=3, ovr=0.4, norm=True, eps=1e-6, padding=0):\n",
    "  N, C, H, W = im_tensor.size()\n",
    "  w = np.minimum(W, H) # window size at scale 1\n",
    "  fea = []\n",
    "  for l in range(l0, l0+L):\n",
    "    wl = int(np.floor(2*w/(l+1))) # window size at scale l\n",
    "    wl = np.maximum(wl, 2)\n",
    "    sl = int(np.floor((1-ovr)*wl)) # stride size at scale l\n",
    "    sl = np.maximum(sl, 1)\n",
    "    pl= padding if padding is not None else sl\n",
    "    xl = F.max_pool2d(im_tensor,\n",
    "                        kernel_size=(wl, wl),\n",
    "                        stride=(sl, sl),\n",
    "                        padding=(pl, pl))   \n",
    "    fea.append(xl.view(N, C, -1))\n",
    "    \n",
    "  fea = torch.cat(fea, dim=2)\n",
    "  fea = fea / (torch.norm(fea, p=2, dim=1, keepdim=True) + eps)\n",
    "  fea = fea.transpose(1, 2) # (N, C, R ) -> (N, R, C)\n",
    "  return fea\n",
    "\n",
    "\n",
    "def get_feature(reg_feat_mat):\n",
    "  reg_feat_mat = reg_feat_mat.squeeze() # [1, r, c] -> [r, c]\n",
    "#   r = reg_feat_mat.size(0)\n",
    "  ag_feat_vec = torch.sum(reg_feat_mat, dim=0, keepdim=False) # (r, c) -> (c,)\n",
    "  ag_feat_vec = ag_feat_vec / (torch.norm(ag_feat_vec,\n",
    "                                            p=2,\n",
    "                                            dim=0,\n",
    "                                            keepdim=True) + 1e-6)\n",
    "  ag_feat_vec=np.array(ag_feat_vec).reshape(1,-1)\n",
    "  return ag_feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im_tensor =  torch.Size([1, 512, 21, 32])\n",
      "feature torch.Size([1, 12, 512])\n",
      "rmac (1, 512)\n"
     ]
    }
   ],
   "source": [
    "#test 1 image\n",
    "model= keras.applications.VGG16(include_top=False,weights=utils.DATA_DIR + utils.WEIGHTS_FILE)\n",
    "file = utils.DATA_DIR + 'sample.jpg'\n",
    "x = preprocessImage(file)\n",
    "im_tensor = model.predict(x)\n",
    "im_tensor=torch.tensor(im_tensor)\n",
    "print(\"im_tensor = \",im_tensor.shape)\n",
    "\n",
    "feature=rzac(im_tensor)\n",
    "print(\"feature\",feature.shape)\n",
    "\n",
    "rmac=get_feature(feature)\n",
    "print(\"rmac\",rmac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_Db(reg_feat_mat):\n",
    "    reg_feat_mat = reg_feat_mat.squeeze() # [1, r, c] -> [r, c]\n",
    "    return reg_feat_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_chanel(tensor_img):\n",
    "    x= np.moveaxis(tensor_img, -1, 0)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(linkImage):\n",
    "    img=cv2.imread(linkImage)\n",
    "    x = change_chanel(img)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Rmac(file,model):\n",
    "    x = preprocessImage(file)\n",
    "    #get feature each tensor image\n",
    "    im_tensor = model.predict(x)\n",
    "    #conver to torch tensor\n",
    "    im_tensor=torch.tensor(im_tensor)\n",
    "    #caculate rzac\n",
    "    reg_feat_mat= rzac(im_tensor)   \n",
    "    #caculate rmac \n",
    "    RMAC = get_feature(reg_feat_mat)\n",
    "    return RMAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Rmac_DB(file,model):\n",
    "    x = preprocessImage(file)\n",
    "    #get feature each tensor image\n",
    "    im_tensor = model.predict(x)\n",
    "    #conver to torch tensor\n",
    "    im_tensor=torch.tensor(im_tensor)\n",
    "    #caculate rzac\n",
    "    reg_feat_mat= rzac(im_tensor)\n",
    "    nVector_represent=get_feature_Db(reg_feat_mat)\n",
    "    return nVector_represent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anlab/Downloads/imageclassification/image_retrieval\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get file query\n",
    "list_files_query=get_file_query()\n",
    "len(list_files_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anlab/Downloads/imageclassification/image_retrieval/keras_rmac\n"
     ]
    }
   ],
   "source": [
    "%cd keras_rmac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "# get file image correspond with query\n",
    "im_list_query=get_image_query(list_files_query)\n",
    "print(len(im_list_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:25<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t1 = datetime.now().time()\n",
    "from tqdm import tqdm\n",
    "vector_query =[]\n",
    "for img in tqdm(im_list_query):\n",
    "    file = path_local+\"Object Dataset/test/oxbuild_images/\"+img\n",
    "    # Load RMAC model\n",
    "    RMAC=get_Rmac(file,model)\n",
    "    vector_query.append(RMAC[-1])\n",
    "t2 = datetime.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5063/5063 [12:30<00:00,  6.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "with open('dataset.pickle',\"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "dataset_new=[]\n",
    "vector_dataset=[]\n",
    "for img in tqdm(dataset):\n",
    "    file = path_local+\"Object Dataset/test/oxbuild_images/\"+img\n",
    "    # Load RMAC model\n",
    "    RMAC_DB=get_Rmac_DB(file,model)\n",
    "    vector_dataset.append(RMAC_DB)\n",
    "    for i in range(RMAC_DB.shape[0]):\n",
    "        dataset_new.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53794"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53794, 512)\n"
     ]
    }
   ],
   "source": [
    "vector_dataset=np.vstack(vector_dataset)\n",
    "print(vector_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vector_query=np.array(vector_query)\n",
    "print(vector_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính giao của 2 array-> kết quả trả về theo thứ tự của array 1\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anlab/Downloads/imageclassification/image_retrieval\n"
     ]
    }
   ],
   "source": [
    "%cd /home/anlab/Downloads/imageclassification/image_retrieval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_good=get_file_name(list_files_query,\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=len(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def map_name(list_files_query,name,vector_query,vector_dataset,dataset_new):\n",
    "  list_ap_name=[]\n",
    "  list_files_name=get_file_name(list_files_query,name)\n",
    "  for i in range(len(list_files_query)):\n",
    "    vector_l2_dataset=np.linalg.norm(vector_query[i]-vector_dataset,axis=-1)\n",
    "    gt=get_image_correspond(list_files_name[i])\n",
    "    toplen_image_query= np.argsort(vector_l2_dataset) \n",
    "    all_image_in_top = toplen_image_query[:topk]\n",
    "    image_correspond = [dataset_new[image] for image in all_image_in_top]\n",
    "    image_correspond = list(OrderedDict.fromkeys(image_correspond))\n",
    "    index=[]\n",
    "    AP=0\n",
    "    for j in range(len(image_correspond)):\n",
    "      if(image_correspond[j] in gt):\n",
    "        index.append(j)\n",
    "    for k in range(len(index)):\n",
    "      AP= AP+ ((k+1)/(index[k]+1))\n",
    "    AP=AP/len(gt)\n",
    "    list_ap_name.append(AP)\n",
    "  map_name=sum(list_ap_name)/len(list_ap_name)\n",
    "  return map_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_good= map_name(list_files_query,\"good\",vector_query,vector_dataset,dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5806122069115497\n"
     ]
    }
   ],
   "source": [
    "print(map_good)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO6YAqcbq+vm2+IagH8h+4A",
   "collapsed_sections": [],
   "name": "image_retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
